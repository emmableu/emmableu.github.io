[
  {
  "key": "wang2020crescendo",
  "month": 3,
  "date": null,
    "highlight": "A self-paced learning tool that allows novice students to do visual and interactive programming, while learning fundamental programming concepts.",
    "pdf": "https://www.researchgate.net/publication/339510447_Crescendo_Engaging_Students_to_Self-Paced_Programming_Practices",
    "talk": "https://www.youtube.com/watch?v=OO10yjXG07w&t=1s",
    "slides": "https://docs.google.com/presentation/d/e/2PACX-1vQI4q3m6oc1sQgVXlHmGf00RIgM-pkuKqXQ7taHf7Y_kQEP_jYv0BFD_10vMdkS765CeLC3l8PdX9Cg/pub?start=false&loop=false&delayms=60000",
    "rate": "31.4% acceptance rate; 171/544 papers.",
    "conferenceKey": "SIGCSE'20",
    "abstractKey": "This paper introduces Crescendo, a self-paced programming practice environment that combines the block-based and visual, interactive programming of Snap, with the structured practices commonly found in Drill-and-Practice Environments. Crescendo supports students with Parsons problems to reduce problem complexity, Use-Modify-Create task progressions to gradually introduce new programming concepts, and automated feedback and assessment to support learning. In this work, we report on our experience deploying Crescendo in a programming camp for middle school students, as well as in an introductory university course for non-majors. Our initial results from field observations and log data suggest that the support features in Crescendo kept students engaged and allowed them to progress through programming concepts quickly. However, some students still struggled even with these highly-structured problems, requiring additional assistance, suggesting that even strong scaffolding may be insufficient to allow students to progress independently through the tasks."
  },
  {
    "key": "wang2020step",
    "month": 6,
    "date": null,
    "highlight": "One challenge with programming Worked Examples is that they are offered prior to problem-solving, and may not help students when they are stuck in the middle of problem-solving. Step Tutor's design borrows insights from programming next-step hints, but teaches one meaningful step at a time.",
    "pdf": "https://www.researchgate.net/publication/340661815_Step_Tutor_Supporting_Students_through_Step-by-Step_Example-Based_Feedback",
    "talk": "https://youtu.be/4uWfUg41sp4",
    "slides": "https://docs.google.com/presentation/d/e/2PACX-1vSd5_bougY0gdeMiEkxMnkwV6y88LOVc0Kai41WVAGeJ1WofMK2ZZVaReFfbDyiKnT62O51UjZYBwVE/pub?start=false&loop=false&delayms=60000",
    "rate": "27.6% acceptance rate; 72/261 full papers.",
    "conferenceKey": "ITiCSE'20",
    "abstractKey": "Students often get stuck when programming independently, and need help to progress. Existing, automated feedback can help students progress, but it is unclear whether it ultimately leads to learning. We present Step Tutor, which helps struggling students during programming by presenting them with relevant, step-by-step examples. The goal of Step Tutor is to help students progress, and engage them in comparison, reflection, and learning. When a student requests help, Step Tutor adaptively selects an example to demonstrate the next meaningful step in the solution. It engages the student in comparing ``before'' and ``after'' code snapshots, and their corresponding visual output, and guides them to reflect on the changes. Step Tutor is a novel form of help that combines effective aspects of existing support features, such as hints and Worked Examples, to help students both progress and learn. To understand how students use Step Tutor, we asked nine undergraduate students to complete two programming tasks, with its help, and interviewed them about their experience. We present our qualitative analysis of students' experience, which shows us why and how they seek help from Step Tutor, and Step Tutor's affordances. These initial results suggest that students perceived that Step Tutor accomplished its goals of helping them to progress and learn."
  },
  {
    "key": "wang2020comparing",
    "month": 7,
    "date": null,
    "highlight": "Syntax-based static code analysis start by representing code as vectors and feeding it into a machine-learning model. What feature engineering approach is ideal when transforming code into vectors? A random sample of 413 highly different Scratch projects is insufficient to tell.",
    "pdf": "https://www.researchgate.net/publication/342927360_Comparing_Feature_Engineering_Approaches_to_Predict_Complex_Programming_Behaviors",
    "talk": "https://youtu.be/f3F3vz5-9Qc",
    "slides": "https://docs.google.com/presentation/d/e/2PACX-1vRW0XuFroTG-zZM6vPjk5bHHFo3aWBIcAwCv4DCmUS-3CVINYNZ9FuMZhFavlhWPvNF-DhX2-z1o79e/pub?start=false&loop=false&delayms=60000",
    "conferenceKey": "CSEDM Workshop @ EDM'20",
    "abstractKey": "Using machine learning to classify student code has many applications in computer science education, such as auto-grading, identifying struggling students from their code, and propagating feedback to address particular misconceptions. However, a fundamental challenge of using machine learning for code classification is how to represent program code as a vector to be processed by modern learning algorithms. A piece of programming code is structurally represented by an abstract syntax tree (AST), and a variety of approaches have been proposed to extract features from these ASTs to use in learning algorithms, but no work has directly compared their effectiveness. In this paper, we do so by comparing three different feature engineering approaches for classifying the behavior of novices' open-ended programming projects according to expert labels. In order to evaluate the effectiveness of these feature engineering approaches, we hand-labeled a dataset of novice programs from the Scratch repository to indicate the presence of five complex, game-related programming behaviors. We compared these feature engineering approaches by evaluating their classification effectiveness. Our results show that the three approaches perform similarly across different target labels. However, we also find evidence that all approaches led to overfitting, suggesting the need for future research to select and reduce code features, which may reveal advantages in more complex feature engineering approaches."
  }

]
